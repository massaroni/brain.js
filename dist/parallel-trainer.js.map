{"version":3,"sources":["../src/parallel-trainer.js"],"names":["trainParallel","unpackTrainOpts","workerFarm","require","workers","resolve","data","net","trainOptions","startMs","Date","now","log","console","logPeriod","parallel","threadLog","NetCtor","Object","getPrototypeOf","constructor","maxEpochs","epochs","errorThresh","trainDefaults","threads","threadCount","length","peerTrainOptions","assign","callback","train","iterations","globalWeights","toJSON","error","itemIterations","promises","thread","syncMode","result","runTrainingSync","type","partition","push","Promise","runTrainingWorker","results","all","maxError","minError","trainedNets","t","trained","status","Math","max","min","avg","slice","testnet","fromJSON","test","endMs","elapsedMs","threadsOpts","Number","isInteger","netCtorName","name","threadsOptsObj","dataUsed","partitioned","types","totalThreads","netName","config","partitions","partitionSize","trainingDataSize","trainingData","unpartitioned","remainingData","splice","Error","shift","netType","netJSON","trainOpts","brainjs","default","ctor","reject","trainedNetJSON"],"mappings":";;;;;;;;QAOsBA,a,GAAAA,a;QAyENC,e,GAAAA,e;;AAhFhB;;;;;;;;AACA,IAAMC,aAAaC,QAAQ,aAAR,CAAnB;AACA,IAAMC,UAAaF,WAAWC,QAAQE,OAAR,CAAgB,2BAAhB,CAAX,CAAnB;;AAEA;;;AAGO,eAAeL,aAAf,CAA6BM,IAA7B,EAAmCC,GAAnC,EAA2D;AAAA,MAAnBC,YAAmB,uEAAJ,EAAI;;AAChE,MAAMC,UAAUC,KAAKC,GAAL,EAAhB;AACA,MAAMC,MAAM,CAACJ,aAAaI,GAAb,KAAqB,IAArB,GAA4BC,QAAQD,GAApC,GAA0CJ,aAAaI,GAAxD,KAAiE,YAAM,CAAE,CAArF;AACA,MAAME,YAAYN,aAAaM,SAAb,IAA0B,CAA5C;AACA,MAAMC,WAAWP,aAAaO,QAAb,IAAyB,EAA1C;AACA,MAAMC,YAAYD,SAASH,GAAT,KAAiB,IAAjB,GAAwBC,QAAQD,GAAhC,GAAsCG,SAASH,GAAjE;AACA,MAAMK,UAAUC,OAAOC,cAAP,CAAsBZ,GAAtB,EAA2Ba,WAA3C;AACA,MAAMC,YAAYN,SAASO,MAAT,IAAmB,IAArC;AACA,MAAMC,cAAcf,aAAae,WAAb,IAA4BN,QAAQO,aAAR,CAAsBD,WAAtE;AACA,MAAME,UAAUxB,gBAAgBO,YAAhB,EAA8BD,GAA9B,EAAmCD,IAAnC,CAAhB;AACA,MAAMoB,cAAcD,QAAQE,MAA5B;;AAEA,MAAIC,mBAAmBV,OAAOW,MAAP,CAAc,EAAd,EAAkBrB,YAAlB,CAAvB;AACA,SAAOoB,iBAAiBb,QAAxB;AACA,SAAOa,iBAAiBE,QAAxB;AACAF,mBAAiBhB,GAAjB,GAAuBI,SAAvB;AACAY,mBAAiBd,SAAjB,GAA6BC,SAASD,SAAtC;;AAEAP,MAAIwB,KAAJ,CAAU,CAACzB,KAAK,CAAL,CAAD,CAAV,EAAqB,EAACiB,aAAa,GAAd,EAAmBS,YAAY,CAA/B,EAArB,EAlBgE,CAkBP;AACzD,MAAIC,gBAAgB1B,IAAI2B,MAAJ,EAApB;;AAEA,MAAIC,QAAQ,CAAZ;AACA,MAAIb,SAAS,CAAb;AACA,MAAIU,aAAa,CAAjB;AACA,MAAII,iBAAiB,CAArB;;AAEA,SAAOd,SAASD,SAAT,IAAsBc,SAASZ,WAAtC,EAAmD;AAAA;;AACjD,QAAIc,WAAW,EAAf;;AADiD;AAAA;AAAA;;AAAA;AAGjD,2BAAmBZ,OAAnB,8HAA4B;AAAA,YAAnBa,MAAmB;;AAC1B,YAAIvB,SAASwB,QAAT,KAAsB,IAA1B,EAAgC;AAC9B,cAAIC,SAASC,gBAAgBH,OAAOI,IAAvB,EAA6BT,aAA7B,EAA4CK,OAAOK,SAAnD,EAA8Df,gBAA9D,CAAb;AACAS,mBAASO,IAAT,CAAcC,QAAQxC,OAAR,CAAgBmC,MAAhB,CAAd;AACD,SAHD,MAGO;AACLH,mBAASO,IAAT,CAAcE,kBAAkBR,OAAOI,IAAzB,EAA+BT,aAA/B,EAA8CK,OAAOK,SAArD,EAAgEf,gBAAhE,CAAd;AACD;AACF;AAVgD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAYjD,QAAMmB,UAAU,MAAMF,QAAQG,GAAR,CAAYX,QAAZ,CAAtB;AACA,QAAIY,iBAAJ;AAAA,QAAcC,iBAAd;AACA,QAAIC,cAAc,EAAlB;AACA,SAAK,IAAIC,IAAI,CAAb,EAAgBA,IAAI1B,WAApB,EAAiC0B,GAAjC,EAAsC;AACpC,UAAMC,WAAUN,QAAQK,CAAR,EAAWC,OAA3B;AACA,UAAMC,SAASP,QAAQK,CAAR,EAAWE,MAA1B;AACAL,iBAAWG,MAAM,CAAN,GAAUE,OAAOnB,KAAjB,GAAyBoB,KAAKC,GAAL,CAASP,QAAT,EAAmBK,OAAOnB,KAA1B,CAApC;AACAe,iBAAWE,MAAM,CAAN,GAAUE,OAAOnB,KAAjB,GAAyBoB,KAAKE,GAAL,CAASP,QAAT,EAAmBI,OAAOnB,KAA1B,CAApC;AACAgB,kBAAYP,IAAZ,CAAiBS,QAAjB;AACArB,oBAAcsB,OAAOtB,UAArB;AACAI,wBAAkBkB,OAAOtB,UAAP,GAAoBP,QAAQ2B,CAAR,EAAWT,SAAX,CAAqBhB,MAA3D;AACD;;AAEDM,oBAAgB,6BAAY,CAAZ,GAAeyB,GAAf,yCAAsBP,YAAYQ,KAAZ,CAAkB,CAAlB,CAAtB,GAA4CzB,MAA5C,EAAhB;;AAEA,QAAIe,YAAY1B,WAAhB,EAA6B;AAC3BY,cAAQc,QAAR;AACD,KAFD,MAEO,IAAIC,YAAY3B,WAAhB,EAA6B;AAClC,UAAMqC,UAAU,IAAI3C,OAAJ,CAAYT,YAAZ,CAAhB;AACAoD,cAAQC,QAAR,CAAiB5B,aAAjB;AACAE,cAAQkB,QAAQS,IAAR,CAAaxD,IAAb,EAAmB6B,KAA3B;AACD;;AAEDb;AACA,QAAIA,SAASR,SAAT,KAAuB,CAA3B,EAA8B;AAC5BF,UAAI,EAACoB,sBAAD,EAAaG,YAAb,EAAoBb,cAApB,EAA4Bc,8BAA5B,EAA4CV,wBAA5C,EAAJ;AACD;AACF;;AAEDnB,MAAIsD,QAAJ,CAAa5B,aAAb;AACA,MAAM8B,QAAQrD,KAAKC,GAAL,EAAd;AACA,MAAMqD,YAAYD,QAAQtD,OAA1B;AACA,SAAO,EAAC0B,YAAD,EAAQH,sBAAR,EAAoBI,8BAApB,EAAoCd,cAApC,EAA4CI,wBAA5C,EAAyDsC,oBAAzD,EAAP;AACD;;AAEM,SAAS/D,eAAT,CAAyBO,YAAzB,EAAuCD,GAAvC,EAA4CD,IAA5C,EAAkD;AACvD,MAAMS,WAAWP,aAAaO,QAAb,IAAyB,EAA1C;AACA,MAAIkD,cAAclD,SAASU,OAA3B;AACA,MAAI,CAACwC,WAAD,IAAgBC,OAAOC,SAAP,CAAiBF,WAAjB,CAApB,EAAmD;AACjD,QAAMG,cAAclD,OAAOC,cAAP,CAAsBZ,GAAtB,EAA2Ba,WAA3B,CAAuCiD,IAA3D;AACA,QAAIC,iBAAiB,EAArB;AACAA,mBAAeF,WAAf,IAA8BH,eAAe,CAA7C;AACAA,kBAAcK,cAAd;AACD;;AAED,MAAIC,WAAW,CAAf;AACA,MAAIC,cAAc,CAAlB;AACA,MAAIC,QAAQ,EAAZ;AACA,MAAIC,eAAe,CAAnB;AACA,OAAK,IAAIC,OAAT,IAAoBV,WAApB,EAAiC;AAC/B,QAAMW,SAASX,YAAYU,OAAZ,CAAf;AACA,QAAIjD,cAAc,CAAlB;AACA,QAAImD,aAAa,IAAjB;AACA,QAAI,QAAOD,MAAP,yCAAOA,MAAP,OAAkB,QAAtB,EAAgC;AAC9B,UAAIE,gBAAgBF,OAAOE,aAA3B;AACApD,oBAAckD,OAAOnD,OAAP,IAAkB,CAAhC;AACA,UAAMsD,mBAAmBxB,KAAKE,GAAL,CAASmB,OAAOG,gBAAP,IAA2B,CAApC,EAAuCzE,KAAKqB,MAAL,GAAc4C,QAArD,CAAzB;;AAEA,UAAIQ,gBAAJ,EAAsB;AACpBP,uBAAe9C,WAAf;AACA,YAAIsD,eAAe1E,KAAKqD,KAAL,CAAWY,QAAX,EAAqBQ,gBAArB,CAAnB;AACAF,qBAAa,yBAAUG,YAAV,EAAwBtD,WAAxB,EAAqCoD,aAArC,CAAb;AACAP,oBAAYQ,gBAAZ;AACD;AACF,KAXD,MAWO,IAAIb,OAAOC,SAAP,CAAiBS,MAAjB,CAAJ,EAA8B;AACnClD,oBAAckD,UAAU,CAAxB;AACD;AACDF,oBAAgBhD,WAAhB;;AAEA+C,UAAM7B,IAAN,CAAW,EAACF,MAAMiC,OAAP,EAAgBjD,wBAAhB,EAA6BmD,sBAA7B,EAAX;AACD;;AAED,MAAMI,gBAAgBP,eAAeF,WAArC;AACA,MAAIS,aAAJ,EAAmB;AACjB,QAAMC,gBAAgBX,aAAa,CAAb,GAAiBjE,IAAjB,GAAwBA,KAAKqD,KAAL,CAAWY,QAAX,CAA9C;AACA,QAAMO,iBAAgB/D,SAAS+D,aAAT,IAA0B,CAAhD;AACA,QAAMD,cAAa,yBAAUK,aAAV,EAAyBD,aAAzB,EAAwCH,cAAxC,CAAnB;AAHiB;AAAA;AAAA;;AAAA;AAIjB,4BAAiBL,KAAjB,mIAAwB;AAAA,YAAf/B,IAAe;;AACtB,YAAI,CAACA,KAAKmC,UAAV,EAAsB;AACpBnC,eAAKmC,UAAL,GAAkBA,YAAWM,MAAX,CAAkB,CAAlB,EAAqBzC,KAAKhB,WAA1B,CAAlB;AACD;AACF;AARgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AASjB,QAAImD,YAAWlD,MAAX,GAAoB,CAAxB,EAA2B;AACzB,YAAM,IAAIyD,KAAJ,CAAU,qBAAV,CAAN;AACD;AACF;;AAED,MAAI3D,UAAU,EAAd;AApDuD;AAAA;AAAA;;AAAA;AAqDvD,0BAAiBgD,KAAjB,mIAAwB;AAAA,UAAf/B,KAAe;;AACtB,UAAImC,eAAanC,MAAKmC,UAAtB;AACA,WAAK,IAAIzB,IAAI,CAAb,EAAgBA,IAAIV,MAAKhB,WAAzB,EAAsC0B,GAAtC,EAA2C;AACzC3B,gBAAQmB,IAAR,CAAa,EAACF,MAAMA,MAAKA,IAAZ,EAAkBC,WAAWkC,aAAWQ,KAAX,EAA7B,EAAb;AACD;AACF;AA1DsD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AA4DvD,SAAO5D,OAAP;AACD;;AAED,SAASgB,eAAT,CAAyB6C,OAAzB,EAAkCC,OAAlC,EAA2CP,YAA3C,EAAyDQ,SAAzD,EAAoE;AAClE,MAAMC,UAAUtF,QAAQ,SAAR,EAAmBuF,OAAnC;AACA,MAAMC,OAAOF,QAAQH,OAAR,CAAb;AACA,MAAMjC,UAAU,IAAIsC,IAAJ,EAAhB;AACAtC,UAAQQ,QAAR,CAAiB0B,OAAjB;AACA,MAAMjC,SAASD,QAAQtB,KAAR,CAAciD,YAAd,EAA4BQ,SAA5B,CAAf;AACA,SAAO,EAAClC,cAAD,EAASD,gBAAT,EAAP;AACD;;AAED,SAASP,iBAAT,CAA2BwC,OAA3B,EAAoCC,OAApC,EAA6CP,YAA7C,EAA2DQ,SAA3D,EAAsE;AACpE,MAAMC,UAAUtF,QAAQ,SAAR,EAAmBuF,OAAnC;AACA,SAAO,IAAI7C,OAAJ,CAAY,UAACxC,OAAD,EAAUuF,MAAV,EAAqB;AACtCxF,YAAQ,EAACkF,gBAAD,EAAUC,gBAAV,EAAmBP,0BAAnB,EAAiCQ,oBAAjC,EAAR,EAAqD,UAACrD,KAAD,EAAQY,OAAR,EAAoB;AACvE,UAAIZ,KAAJ,EAAW;AACT,eAAOyD,OAAOzD,KAAP,CAAP;AACD;;AAED,UAAMkB,UAAU,IAAIoC,QAAQH,OAAR,CAAJ,EAAhB;AACAjC,cAAQQ,QAAR,CAAiBd,QAAQ8C,cAAzB;;AAEAxF,cAAQ,EAACgD,gBAAD,EAAUC,QAAQP,QAAQO,MAA1B,EAAR;AACD,KATD;AAUD,GAXM,CAAP;AAYD","file":"parallel-trainer.js","sourcesContent":["import partition from './utilities/partition';\nconst workerFarm = require('worker-farm');\nconst workers    = workerFarm(require.resolve('./parallel-trainer-worker'));\n\n/**\n * Ensemble training, via simple parameter averaging.\n */\nexport async function trainParallel(data, net, trainOptions = {}) {\n  const startMs = Date.now();\n  const log = (trainOptions.log === true ? console.log : trainOptions.log) || (() => {});\n  const logPeriod = trainOptions.logPeriod || 1;\n  const parallel = trainOptions.parallel || {};\n  const threadLog = parallel.log === true ? console.log : parallel.log;\n  const NetCtor = Object.getPrototypeOf(net).constructor;\n  const maxEpochs = parallel.epochs || 1000;\n  const errorThresh = trainOptions.errorThresh || NetCtor.trainDefaults.errorThresh;\n  const threads = unpackTrainOpts(trainOptions, net, data);\n  const threadCount = threads.length;\n\n  let peerTrainOptions = Object.assign({}, trainOptions);\n  delete peerTrainOptions.parallel;\n  delete peerTrainOptions.callback;\n  peerTrainOptions.log = threadLog;\n  peerTrainOptions.logPeriod = parallel.logPeriod;\n  \n  net.train([data[0]], {errorThresh: 0.9, iterations: 1}); // initialize weights\n  let globalWeights = net.toJSON();\n\n  let error = 1;\n  let epochs = 0;\n  let iterations = 0;\n  let itemIterations = 0;\n\n  while (epochs < maxEpochs && error >= errorThresh) {\n    let promises = [];\n\n    for (let thread of threads) {\n      if (parallel.syncMode === true) {\n        let result = runTrainingSync(thread.type, globalWeights, thread.partition, peerTrainOptions);\n        promises.push(Promise.resolve(result));\n      } else {\n        promises.push(runTrainingWorker(thread.type, globalWeights, thread.partition, peerTrainOptions));\n      }\n    }\n\n    const results = await Promise.all(promises);\n    let maxError, minError;\n    let trainedNets = [];\n    for (let t = 0; t < threadCount; t++) {\n      const trained = results[t].trained;\n      const status = results[t].status;\n      maxError = t === 0 ? status.error : Math.max(maxError, status.error);\n      minError = t === 0 ? status.error : Math.min(minError, status.error);\n      trainedNets.push(trained);\n      iterations += status.iterations;\n      itemIterations += status.iterations * threads[t].partition.length;\n    }\n\n    globalWeights = trainedNets[0].avg(...trainedNets.slice(1)).toJSON();\n\n    if (maxError <= errorThresh) {\n      error = maxError;\n    } else if (minError <= errorThresh) {\n      const testnet = new NetCtor(trainOptions);\n      testnet.fromJSON(globalWeights);\n      error = trained.test(data).error;\n    }\n    \n    epochs++;\n    if (epochs % logPeriod === 0) {\n      log({iterations, error, epochs, itemIterations, threadCount});\n    }\n  }\n\n  net.fromJSON(globalWeights);\n  const endMs = Date.now();\n  const elapsedMs = endMs - startMs;\n  return {error, iterations, itemIterations, epochs, threadCount, elapsedMs};\n}\n\nexport function unpackTrainOpts(trainOptions, net, data) {\n  const parallel = trainOptions.parallel || {};\n  let threadsOpts = parallel.threads;\n  if (!threadsOpts || Number.isInteger(threadsOpts)) {\n    const netCtorName = Object.getPrototypeOf(net).constructor.name;\n    let threadsOptsObj = {};\n    threadsOptsObj[netCtorName] = threadsOpts || 1;\n    threadsOpts = threadsOptsObj;\n  }\n\n  let dataUsed = 0;\n  let partitioned = 0;\n  let types = [];\n  let totalThreads = 0;\n  for (let netName in threadsOpts) {\n    const config = threadsOpts[netName];\n    let threadCount = 1;\n    let partitions = null;\n    if (typeof config === \"object\") {\n      let partitionSize = config.partitionSize;\n      threadCount = config.threads || 1;\n      const trainingDataSize = Math.min(config.trainingDataSize || 0, data.length - dataUsed);\n\n      if (trainingDataSize) {\n        partitioned += threadCount;\n        let trainingData = data.slice(dataUsed, trainingDataSize);\n        partitions = partition(trainingData, threadCount, partitionSize);\n        dataUsed += trainingDataSize;\n      }\n    } else if (Number.isInteger(config)) {\n      threadCount = config || 1;\n    }\n    totalThreads += threadCount;\n\n    types.push({type: netName, threadCount, partitions});\n  }\n\n  const unpartitioned = totalThreads - partitioned;\n  if (unpartitioned) {\n    const remainingData = dataUsed === 0 ? data : data.slice(dataUsed);\n    const partitionSize = parallel.partitionSize || 1;\n    const partitions = partition(remainingData, unpartitioned, partitionSize);\n    for (let type of types) {\n      if (!type.partitions) {\n        type.partitions = partitions.splice(0, type.threadCount);\n      }\n    }\n    if (partitions.length > 0) {\n      throw new Error('Too many partitions');\n    }\n  }\n\n  let threads = [];\n  for (let type of types) {\n    let partitions = type.partitions;\n    for (let t = 0; t < type.threadCount; t++) {\n      threads.push({type: type.type, partition: partitions.shift()});\n    }\n  }\n\n  return threads;\n}\n\nfunction runTrainingSync(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  const ctor = brainjs[netType];\n  const trained = new ctor();\n  trained.fromJSON(netJSON);\n  const status = trained.train(trainingData, trainOpts);\n  return {status, trained};\n}\n\nfunction runTrainingWorker(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  return new Promise((resolve, reject) => {\n    workers({netType, netJSON, trainingData, trainOpts}, (error, results) => {\n      if (error) {\n        return reject(error);\n      }\n\n      const trained = new brainjs[netType]();\n      trained.fromJSON(results.trainedNetJSON);\n\n      resolve({trained, status: results.status});\n    });\n  });\n}\n"]}