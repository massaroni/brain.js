{"version":3,"sources":["../src/parallel-trainer.js"],"names":["trainParallel","unpackTrainOpts","workerFarm","require","workers","resolve","data","net","trainOpts","startMs","Date","now","log","console","logPeriod","parallel","threadLog","NetCtor","Object","getPrototypeOf","constructor","maxEpochs","epochs","errorThresh","trainDefaults","threads","threadCount","length","threadTrainOpts","assign","callback","timeout","Infinity","Number","MAX_SAFE_INTEGER","verifyIsInitialized","globalWeights","toJSON","error","iterations","itemIterations","promises","thread","syncMode","result","runTrainingSync","type","partition","push","Promise","runTrainingWorker","results","all","maxError","minError","trainedNets","t","trained","status","Math","max","min","avg","slice","errorMode","testnet","fromJSON","testResult","test","endMs","elapsedMs","trainOptions","threadsOpts","isInteger","netCtorName","name","threadsOptsObj","dataUsed","partitioned","types","totalThreads","netName","config","partitions","partitionSize","trainingDataSize","trainingData","unpartitioned","remainingData","splice","Error","shift","netType","netJSON","brainjs","default","ctor","train","reject","trainedNetJSON"],"mappings":";;;;;;;;QAOsBA,a,GAAAA,a;QA8ENC,e,GAAAA,e;;AArFhB;;;;;;;;AACA,IAAMC,aAAaC,QAAQ,aAAR,CAAnB;AACA,IAAMC,UAAaF,WAAWC,QAAQE,OAAR,CAAgB,2BAAhB,CAAX,CAAnB;;AAEA;;;AAGO,eAAeL,aAAf,CAA6BM,IAA7B,EAAmCC,GAAnC,EAAwD;AAAA,MAAhBC,SAAgB,uEAAJ,EAAI;;AAC7D,MAAMC,UAAUC,KAAKC,GAAL,EAAhB;AACA,MAAMC,MAAM,CAACJ,UAAUI,GAAV,KAAkB,IAAlB,GAAyBC,QAAQD,GAAjC,GAAuCJ,UAAUI,GAAlD,KAA2D,YAAM,CAAE,CAA/E;AACA,MAAME,YAAYN,UAAUM,SAAV,IAAuB,CAAzC;AACA,MAAMC,WAAWP,UAAUO,QAAV,IAAsB,EAAvC;AACA,MAAMC,YAAYD,SAASH,GAAT,KAAiB,IAAjB,GAAwBC,QAAQD,GAAhC,GAAsCG,SAASH,GAAT,IAAgB,KAAxE;AACA,MAAMK,UAAUC,OAAOC,cAAP,CAAsBZ,GAAtB,EAA2Ba,WAA3C;AACA,MAAMC,YAAYN,SAASO,MAAT,IAAmB,IAArC;AACA,MAAMC,cAAcf,UAAUe,WAAV,IAAyBN,QAAQO,aAAR,CAAsBD,WAAnE;AACA,MAAME,UAAUxB,gBAAgBO,SAAhB,EAA2BD,GAA3B,EAAgCD,IAAhC,CAAhB;AACA,MAAMoB,cAAcD,QAAQE,MAA5B;;AAEA,MAAIC,kBAAkBV,OAAOW,MAAP,CAAc,EAAd,EAAkBrB,SAAlB,CAAtB;AACA,SAAOoB,gBAAgBb,QAAvB;AACA,SAAOa,gBAAgBE,QAAvB;AACAF,kBAAgBhB,GAAhB,GAAsBI,SAAtB;AACAY,kBAAgBd,SAAhB,GAA4BC,SAASD,SAAT,IAAsB,CAAlD;AACAc,kBAAgBG,OAAhB,GAA0B,CAACH,gBAAgBG,OAAjB,IAA4BH,gBAAgBG,OAAhB,KAA4BC,QAAxD,GAAmEC,OAAOC,gBAA1E,GAA6FN,gBAAgBG,OAAvI;;AAEAxB,MAAI4B,mBAAJ,CAAwB7B,IAAxB;AACA,MAAI8B,gBAAgB7B,IAAI8B,MAAJ,EAApB;;AAEA,MAAIC,QAAQ,CAAZ;AACA,MAAIhB,SAAS,CAAb;AACA,MAAIiB,aAAa,CAAjB;AACA,MAAIC,iBAAiB,CAArB;;AAEA,SAAOlB,SAASD,SAAT,IAAsBiB,SAASf,WAAtC,EAAmD;AAAA;;AACjD,QAAIkB,WAAW,EAAf;;AADiD;AAAA;AAAA;;AAAA;AAGjD,2BAAmBhB,OAAnB,8HAA4B;AAAA,YAAnBiB,MAAmB;;AAC1B,YAAI3B,SAAS4B,QAAT,KAAsB,IAA1B,EAAgC;AAC9B,cAAIC,SAASC,gBAAgBH,OAAOI,IAAvB,EAA6BV,aAA7B,EAA4CM,OAAOK,SAAnD,EAA8DnB,eAA9D,CAAb;AACAa,mBAASO,IAAT,CAAcC,QAAQ5C,OAAR,CAAgBuC,MAAhB,CAAd;AACD,SAHD,MAGO;AACLH,mBAASO,IAAT,CAAcE,kBAAkBR,OAAOI,IAAzB,EAA+BV,aAA/B,EAA8CM,OAAOK,SAArD,EAAgEnB,eAAhE,CAAd;AACD;AACF;AAVgD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAYjD,QAAMuB,UAAU,MAAMF,QAAQG,GAAR,CAAYX,QAAZ,CAAtB;AACA,QAAIY,iBAAJ;AAAA,QAAcC,iBAAd;AACA,QAAIC,cAAc,EAAlB;AACA,SAAK,IAAIC,IAAI,CAAb,EAAgBA,IAAI9B,WAApB,EAAiC8B,GAAjC,EAAsC;AACpC,UAAMC,UAAUN,QAAQK,CAAR,EAAWC,OAA3B;AACA,UAAMC,SAASP,QAAQK,CAAR,EAAWE,MAA1B;AACAL,iBAAWG,MAAM,CAAN,GAAUE,OAAOpB,KAAjB,GAAyBqB,KAAKC,GAAL,CAASP,QAAT,EAAmBK,OAAOpB,KAA1B,CAApC;AACAgB,iBAAWE,MAAM,CAAN,GAAUE,OAAOpB,KAAjB,GAAyBqB,KAAKE,GAAL,CAASP,QAAT,EAAmBI,OAAOpB,KAA1B,CAApC;AACAiB,kBAAYP,IAAZ,CAAiBS,OAAjB;AACAlB,oBAAcmB,OAAOnB,UAArB;AACAC,wBAAkBkB,OAAOnB,UAAP,GAAoBd,QAAQ+B,CAAR,EAAWT,SAAX,CAAqBpB,MAA3D;AACD;;AAEDS,oBAAgB,6BAAY,CAAZ,GAAe0B,GAAf,yCAAsBP,YAAYQ,KAAZ,CAAkB,CAAlB,CAAtB,GAA4C1B,MAA5C,EAAhB;;AAEAC,YAAQe,QAAR;AACA,QAAIC,YAAY/B,WAAhB,EAA6B;AAC3B,UAAIR,SAASiD,SAAT,KAAuB,MAA3B,EAAmC;AACjC,YAAMC,UAAU,IAAIhD,OAAJ,EAAhB;AACAgD,gBAAQC,QAAR,CAAiB9B,aAAjB;AACA,YAAM+B,aAAaF,QAAQG,IAAR,CAAa9D,IAAb,CAAnB;AACAgC,gBAAQqB,KAAKC,GAAL,CAAStB,KAAT,EAAgB6B,WAAW7B,KAA3B,CAAR;AACD,OALD,MAKO;AACLA,gBAAQgB,QAAR;AACD;AACF;;AAEDhC;AACA,QAAIA,SAASR,SAAT,KAAuB,CAA3B,EAA8B;AAC5BF,UAAI,EAAC2B,sBAAD,EAAaD,YAAb,EAAoBhB,cAApB,EAA4BkB,8BAA5B,EAA4Cd,wBAA5C,EAAyDU,4BAAzD,EAAJ;AACD;AACF;;AAED7B,MAAI2D,QAAJ,CAAa9B,aAAb;AACA,MAAMiC,QAAQ3D,KAAKC,GAAL,EAAd;AACA,MAAM2D,YAAYD,QAAQ5D,OAA1B;AACA,SAAO,EAAC6B,YAAD,EAAQC,sBAAR,EAAoBC,8BAApB,EAAoClB,cAApC,EAA4CI,wBAA5C,EAAyD4C,oBAAzD,EAAP;AACD;;AAEM,SAASrE,eAAT,CAAyBsE,YAAzB,EAAuChE,GAAvC,EAA4CD,IAA5C,EAAkD;AACvD,MAAMS,WAAWwD,aAAaxD,QAAb,IAAyB,EAA1C;AACA,MAAIyD,cAAczD,SAASU,OAA3B;AACA,MAAI,CAAC+C,WAAD,IAAgBvC,OAAOwC,SAAP,CAAiBD,WAAjB,CAApB,EAAmD;AACjD,QAAME,cAAcxD,OAAOC,cAAP,CAAsBZ,GAAtB,EAA2Ba,WAA3B,CAAuCuD,IAA3D;AACA,QAAIC,iBAAiB,EAArB;AACAA,mBAAeF,WAAf,IAA8BF,eAAe,CAA7C;AACAA,kBAAcI,cAAd;AACD;;AAED,MAAIC,WAAW,CAAf;AACA,MAAIC,cAAc,CAAlB;AACA,MAAIC,QAAQ,EAAZ;AACA,MAAIC,eAAe,CAAnB;AACA,OAAK,IAAIC,OAAT,IAAoBT,WAApB,EAAiC;AAC/B,QAAMU,SAASV,YAAYS,OAAZ,CAAf;AACA,QAAIvD,cAAc,CAAlB;AACA,QAAIyD,aAAa,IAAjB;AACA,QAAI,QAAOD,MAAP,yCAAOA,MAAP,OAAkB,QAAtB,EAAgC;AAC9B,UAAIE,gBAAgBF,OAAOE,aAA3B;AACA1D,oBAAcwD,OAAOzD,OAAP,IAAkB,CAAhC;AACA,UAAM4D,mBAAmB1B,KAAKE,GAAL,CAASqB,OAAOG,gBAAP,IAA2B,CAApC,EAAuC/E,KAAKqB,MAAL,GAAckD,QAArD,CAAzB;;AAEA,UAAIQ,gBAAJ,EAAsB;AACpBP,uBAAepD,WAAf;AACA,YAAI4D,eAAehF,KAAKyD,KAAL,CAAWc,QAAX,EAAqBQ,gBAArB,CAAnB;AACAF,qBAAa,yBAAUG,YAAV,EAAwB5D,WAAxB,EAAqC0D,aAArC,CAAb;AACAP,oBAAYQ,gBAAZ;AACD;AACF,KAXD,MAWO,IAAIpD,OAAOwC,SAAP,CAAiBS,MAAjB,CAAJ,EAA8B;AACnCxD,oBAAcwD,UAAU,CAAxB;AACD;AACDF,oBAAgBtD,WAAhB;;AAEAqD,UAAM/B,IAAN,CAAW,EAACF,MAAMmC,OAAP,EAAgBvD,wBAAhB,EAA6ByD,sBAA7B,EAAX;AACD;;AAED,MAAMI,gBAAgBP,eAAeF,WAArC;AACA,MAAIS,aAAJ,EAAmB;AACjB,QAAMC,gBAAgBX,aAAa,CAAb,GAAiBvE,IAAjB,GAAwBA,KAAKyD,KAAL,CAAWc,QAAX,CAA9C;AACA,QAAMO,iBAAgBrE,SAASqE,aAAT,IAA0B,CAAhD;AACA,QAAMD,cAAa,yBAAUK,aAAV,EAAyBD,aAAzB,EAAwCH,cAAxC,CAAnB;AAHiB;AAAA;AAAA;;AAAA;AAIjB,4BAAiBL,KAAjB,mIAAwB;AAAA,YAAfjC,IAAe;;AACtB,YAAI,CAACA,KAAKqC,UAAV,EAAsB;AACpBrC,eAAKqC,UAAL,GAAkBA,YAAWM,MAAX,CAAkB,CAAlB,EAAqB3C,KAAKpB,WAA1B,CAAlB;AACD;AACF;AARgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AASjB,QAAIyD,YAAWxD,MAAX,GAAoB,CAAxB,EAA2B;AACzB,YAAM,IAAI+D,KAAJ,CAAU,qBAAV,CAAN;AACD;AACF;;AAED,MAAIjE,UAAU,EAAd;AApDuD;AAAA;AAAA;;AAAA;AAqDvD,0BAAiBsD,KAAjB,mIAAwB;AAAA,UAAfjC,KAAe;;AACtB,UAAIqC,eAAarC,MAAKqC,UAAtB;AACA,WAAK,IAAI3B,IAAI,CAAb,EAAgBA,IAAIV,MAAKpB,WAAzB,EAAsC8B,GAAtC,EAA2C;AACzC/B,gBAAQuB,IAAR,CAAa,EAACF,MAAMA,MAAKA,IAAZ,EAAkBC,WAAWoC,aAAWQ,KAAX,EAA7B,EAAb;AACD;AACF;AA1DsD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AA4DvD,SAAOlE,OAAP;AACD;;AAED,SAASoB,eAAT,CAAyB+C,OAAzB,EAAkCC,OAAlC,EAA2CP,YAA3C,EAAyD9E,SAAzD,EAAoE;AAClE,MAAMsF,UAAU3F,QAAQ,SAAR,EAAmB4F,OAAnC;AACA,MAAMC,OAAOF,QAAQF,OAAR,CAAb;AACA,MAAMnC,UAAU,IAAIuC,IAAJ,EAAhB;AACAvC,UAAQS,QAAR,CAAiB2B,OAAjB;AACA,MAAMnC,SAASD,QAAQwC,KAAR,CAAcX,YAAd,EAA4B9E,SAA5B,CAAf;AACA,SAAO,EAACkD,cAAD,EAASD,gBAAT,EAAP;AACD;;AAED,SAASP,iBAAT,CAA2B0C,OAA3B,EAAoCC,OAApC,EAA6CP,YAA7C,EAA2D9E,SAA3D,EAAsE;AACpE,MAAMsF,UAAU3F,QAAQ,SAAR,EAAmB4F,OAAnC;AACA,SAAO,IAAI9C,OAAJ,CAAY,UAAC5C,OAAD,EAAU6F,MAAV,EAAqB;AACtC9F,YAAQ,EAACwF,gBAAD,EAAUC,gBAAV,EAAmBP,0BAAnB,EAAiC9E,oBAAjC,EAAR,EAAqD,UAAC8B,KAAD,EAAQa,OAAR,EAAoB;AACvE,UAAIb,KAAJ,EAAW;AACT,eAAO4D,OAAO5D,KAAP,CAAP;AACD;;AAED,UAAMmB,UAAU,IAAIqC,QAAQF,OAAR,CAAJ,EAAhB;AACAnC,cAAQS,QAAR,CAAiBf,QAAQgD,cAAzB;;AAEA9F,cAAQ,EAACoD,gBAAD,EAAUC,QAAQP,QAAQO,MAA1B,EAAR;AACD,KATD;AAUD,GAXM,CAAP;AAYD","file":"parallel-trainer.js","sourcesContent":["import partition from './utilities/partition';\nconst workerFarm = require('worker-farm');\nconst workers    = workerFarm(require.resolve('./parallel-trainer-worker'));\n\n/**\n * Ensemble training, via simple parameter averaging.\n */\nexport async function trainParallel(data, net, trainOpts = {}) {\n  const startMs = Date.now();\n  const log = (trainOpts.log === true ? console.log : trainOpts.log) || (() => {});\n  const logPeriod = trainOpts.logPeriod || 1;\n  const parallel = trainOpts.parallel || {};\n  const threadLog = parallel.log === true ? console.log : parallel.log || false;\n  const NetCtor = Object.getPrototypeOf(net).constructor;\n  const maxEpochs = parallel.epochs || 1000;\n  const errorThresh = trainOpts.errorThresh || NetCtor.trainDefaults.errorThresh;\n  const threads = unpackTrainOpts(trainOpts, net, data);\n  const threadCount = threads.length;\n\n  let threadTrainOpts = Object.assign({}, trainOpts);\n  delete threadTrainOpts.parallel;\n  delete threadTrainOpts.callback;\n  threadTrainOpts.log = threadLog;\n  threadTrainOpts.logPeriod = parallel.logPeriod || 1;\n  threadTrainOpts.timeout = !threadTrainOpts.timeout || threadTrainOpts.timeout === Infinity ? Number.MAX_SAFE_INTEGER : threadTrainOpts.timeout;\n  \n  net.verifyIsInitialized(data);\n  let globalWeights = net.toJSON();\n\n  let error = 1;\n  let epochs = 0;\n  let iterations = 0;\n  let itemIterations = 0;\n\n  while (epochs < maxEpochs && error >= errorThresh) {\n    let promises = [];\n\n    for (let thread of threads) {\n      if (parallel.syncMode === true) {\n        let result = runTrainingSync(thread.type, globalWeights, thread.partition, threadTrainOpts);\n        promises.push(Promise.resolve(result));\n      } else {\n        promises.push(runTrainingWorker(thread.type, globalWeights, thread.partition, threadTrainOpts));\n      }\n    }\n\n    const results = await Promise.all(promises);\n    let maxError, minError;\n    let trainedNets = [];\n    for (let t = 0; t < threadCount; t++) {\n      const trained = results[t].trained;\n      const status = results[t].status;\n      maxError = t === 0 ? status.error : Math.max(maxError, status.error);\n      minError = t === 0 ? status.error : Math.min(minError, status.error);\n      trainedNets.push(trained);\n      iterations += status.iterations;\n      itemIterations += status.iterations * threads[t].partition.length;\n    }\n\n    globalWeights = trainedNets[0].avg(...trainedNets.slice(1)).toJSON();\n\n    error = maxError;\n    if (minError <= errorThresh) {\n      if (parallel.errorMode === 'test') {\n        const testnet = new NetCtor();\n        testnet.fromJSON(globalWeights);\n        const testResult = testnet.test(data);\n        error = Math.max(error, testResult.error);\n      } else {\n        error = minError;\n      }\n    }\n    \n    epochs++;\n    if (epochs % logPeriod === 0) {\n      log({iterations, error, epochs, itemIterations, threadCount, globalWeights});\n    }\n  }\n\n  net.fromJSON(globalWeights);\n  const endMs = Date.now();\n  const elapsedMs = endMs - startMs;\n  return {error, iterations, itemIterations, epochs, threadCount, elapsedMs};\n}\n\nexport function unpackTrainOpts(trainOptions, net, data) {\n  const parallel = trainOptions.parallel || {};\n  let threadsOpts = parallel.threads;\n  if (!threadsOpts || Number.isInteger(threadsOpts)) {\n    const netCtorName = Object.getPrototypeOf(net).constructor.name;\n    let threadsOptsObj = {};\n    threadsOptsObj[netCtorName] = threadsOpts || 1;\n    threadsOpts = threadsOptsObj;\n  }\n\n  let dataUsed = 0;\n  let partitioned = 0;\n  let types = [];\n  let totalThreads = 0;\n  for (let netName in threadsOpts) {\n    const config = threadsOpts[netName];\n    let threadCount = 1;\n    let partitions = null;\n    if (typeof config === \"object\") {\n      let partitionSize = config.partitionSize;\n      threadCount = config.threads || 1;\n      const trainingDataSize = Math.min(config.trainingDataSize || 0, data.length - dataUsed);\n\n      if (trainingDataSize) {\n        partitioned += threadCount;\n        let trainingData = data.slice(dataUsed, trainingDataSize);\n        partitions = partition(trainingData, threadCount, partitionSize);\n        dataUsed += trainingDataSize;\n      }\n    } else if (Number.isInteger(config)) {\n      threadCount = config || 1;\n    }\n    totalThreads += threadCount;\n\n    types.push({type: netName, threadCount, partitions});\n  }\n\n  const unpartitioned = totalThreads - partitioned;\n  if (unpartitioned) {\n    const remainingData = dataUsed === 0 ? data : data.slice(dataUsed);\n    const partitionSize = parallel.partitionSize || 1;\n    const partitions = partition(remainingData, unpartitioned, partitionSize);\n    for (let type of types) {\n      if (!type.partitions) {\n        type.partitions = partitions.splice(0, type.threadCount);\n      }\n    }\n    if (partitions.length > 0) {\n      throw new Error('Too many partitions');\n    }\n  }\n\n  let threads = [];\n  for (let type of types) {\n    let partitions = type.partitions;\n    for (let t = 0; t < type.threadCount; t++) {\n      threads.push({type: type.type, partition: partitions.shift()});\n    }\n  }\n\n  return threads;\n}\n\nfunction runTrainingSync(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  const ctor = brainjs[netType];\n  const trained = new ctor();\n  trained.fromJSON(netJSON);\n  const status = trained.train(trainingData, trainOpts);\n  return {status, trained};\n}\n\nfunction runTrainingWorker(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  return new Promise((resolve, reject) => {\n    workers({netType, netJSON, trainingData, trainOpts}, (error, results) => {\n      if (error) {\n        return reject(error);\n      }\n\n      const trained = new brainjs[netType]();\n      trained.fromJSON(results.trainedNetJSON);\n\n      resolve({trained, status: results.status});\n    });\n  });\n}\n"]}