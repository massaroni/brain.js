{"version":3,"sources":["../src/parallel-trainer.js"],"names":["trainParallel","unpackTrainOpts","workerFarm","require","workers","resolve","data","net","trainOpts","startMs","Date","now","log","console","logPeriod","parallel","threadLog","NetCtor","Object","getPrototypeOf","constructor","maxEpochs","iterations","errorThresh","trainDefaults","threads","threadCount","length","threadTrainOpts","assign","callback","iterationsPerThread","timeout","Infinity","Number","MAX_SAFE_INTEGER","verifyIsInitialized","globalWeights","toJSON","error","epochs","itemIterations","promises","thread","synchronous","result","runTrainingSync","type","partition","push","Promise","runTrainingWorker","results","all","maxError","minError","trainedNets","t","trained","status","Math","max","min","avg","slice","errorMode","testnet","fromJSON","testResult","test","threadIterations","trainedNetJSON","endMs","elapsedMs","trainOptions","threadsOpts","isInteger","netCtorName","name","threadsOptsObj","dataUsed","partitioned","types","totalThreads","netName","config","partitions","partitionSize","trainingDataSize","trainingData","unpartitioned","remainingData","splice","Error","shift","netType","netJSON","brainjs","default","ctor","train","reject"],"mappings":";;;;;;;;QAOsBA,a,GAAAA,a;QAyFNC,e,GAAAA,e;;AAhGhB;;;;;;;;AACA,IAAMC,aAAaC,QAAQ,aAAR,CAAnB;AACA,IAAMC,UAAaF,WAAWC,QAAQE,OAAR,CAAgB,2BAAhB,CAAX,CAAnB;;AAEA;;;AAGO,eAAeL,aAAf,CAA6BM,IAA7B,EAAmCC,GAAnC,EAAwD;AAAA,MAAhBC,SAAgB,uEAAJ,EAAI;;AAC7D,MAAMC,UAAUC,KAAKC,GAAL,EAAhB;AACA,MAAMC,MAAM,CAACJ,UAAUI,GAAV,KAAkB,IAAlB,GAAyBC,QAAQD,GAAjC,GAAuCJ,UAAUI,GAAlD,KAA2D,YAAM,CAAE,CAA/E;AACA,MAAME,YAAYN,UAAUM,SAAV,IAAuB,CAAzC;AACA,MAAMC,WAAWP,UAAUO,QAAV,IAAsB,EAAvC;AACA,MAAMC,YAAYD,SAASH,GAAT,KAAiB,IAAjB,GAAwBC,QAAQD,GAAhC,GAAsCG,SAASH,GAAT,IAAgB,KAAxE;AACA,MAAMK,UAAUC,OAAOC,cAAP,CAAsBZ,GAAtB,EAA2Ba,WAA3C;AACA,MAAMC,YAAYb,UAAUc,UAAV,IAAwB,IAA1C;AACA,MAAMC,cAAcf,UAAUe,WAAV,IAAyBN,QAAQO,aAAR,CAAsBD,WAAnE;AACA,MAAME,UAAUxB,gBAAgBO,SAAhB,EAA2BD,GAA3B,EAAgCD,IAAhC,CAAhB;AACA,MAAMoB,cAAcD,QAAQE,MAA5B;;AAEA,MAAIC,kBAAkBV,OAAOW,MAAP,CAAc,EAAd,EAAkBrB,SAAlB,CAAtB;AACA,SAAOoB,gBAAgBb,QAAvB;AACA,SAAOa,gBAAgBE,QAAvB;AACAF,kBAAgBN,UAAhB,GAA6BP,SAASgB,mBAAT,IAAgC,EAA7D;AACAH,kBAAgBhB,GAAhB,GAAsBI,SAAtB;AACAY,kBAAgBd,SAAhB,GAA4BC,SAASD,SAAT,IAAsB,CAAlD;AACAc,kBAAgBI,OAAhB,GAA0B,CAACJ,gBAAgBI,OAAjB,IAA4BJ,gBAAgBI,OAAhB,KAA4BC,QAAxD,GAAmEC,OAAOC,gBAA1E,GAA6FP,gBAAgBI,OAAvI;;AAEAzB,MAAI6B,mBAAJ,CAAwB9B,IAAxB;AACA,MAAI+B,gBAAgB9B,IAAI+B,MAAJ,EAApB;;AAEA,MAAIC,QAAQ,CAAZ;AACA,MAAIC,SAAS,CAAb;AACA,MAAIlB,aAAa,CAAjB;AACA,MAAImB,iBAAiB,CAArB;;AAEA,SAAOD,SAASnB,SAAT,IAAsBkB,SAAShB,WAAtC,EAAmD;AAAA;;AACjD,QAAImB,WAAW,EAAf;;AADiD;AAAA;AAAA;;AAAA;AAGjD,2BAAmBjB,OAAnB,8HAA4B;AAAA,YAAnBkB,MAAmB;;AAC1B,YAAI5B,SAAS6B,WAAT,KAAyB,IAA7B,EAAmC;AACjC,cAAIC,SAASC,gBAAgBH,OAAOI,IAAvB,EAA6BV,aAA7B,EAA4CM,OAAOK,SAAnD,EAA8DpB,eAA9D,CAAb;AACAc,mBAASO,IAAT,CAAcC,QAAQ7C,OAAR,CAAgBwC,MAAhB,CAAd;AACD,SAHD,MAGO;AACLH,mBAASO,IAAT,CAAcE,kBAAkBR,OAAOI,IAAzB,EAA+BV,aAA/B,EAA8CM,OAAOK,SAArD,EAAgEpB,eAAhE,CAAd;AACD;AACF;AAVgD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAYjD,QAAMwB,UAAU,MAAMF,QAAQG,GAAR,CAAYX,QAAZ,CAAtB;AACA,QAAIY,iBAAJ;AAAA,QAAcC,iBAAd;AACA,QAAIC,cAAc,EAAlB;AACA,SAAK,IAAIC,IAAI,CAAb,EAAgBA,IAAI/B,WAApB,EAAiC+B,GAAjC,EAAsC;AACpC,UAAMC,UAAUN,QAAQK,CAAR,EAAWC,OAA3B;AACA,UAAMC,SAASP,QAAQK,CAAR,EAAWE,MAA1B;AACAL,iBAAWG,MAAM,CAAN,GAAUE,OAAOpB,KAAjB,GAAyBqB,KAAKC,GAAL,CAASP,QAAT,EAAmBK,OAAOpB,KAA1B,CAApC;AACAgB,iBAAWE,MAAM,CAAN,GAAUE,OAAOpB,KAAjB,GAAyBqB,KAAKE,GAAL,CAASP,QAAT,EAAmBI,OAAOpB,KAA1B,CAApC;AACAiB,kBAAYP,IAAZ,CAAiBS,OAAjB;AACApC,oBAAcqC,OAAOrC,UAArB;AACAmB,wBAAkBkB,OAAOrC,UAAP,GAAoBG,QAAQgC,CAAR,EAAWT,SAAX,CAAqBrB,MAA3D;AACD;;AAEDU,oBAAgB,6BAAY,CAAZ,GAAe0B,GAAf,yCAAsBP,YAAYQ,KAAZ,CAAkB,CAAlB,CAAtB,GAA4C1B,MAA5C,EAAhB;;AAEAC,YAAQe,QAAR;AACA,QAAIC,YAAYhC,WAAhB,EAA6B;AAC3B,UAAIR,SAASkD,SAAT,KAAuB,MAA3B,EAAmC;AACjC,YAAMC,UAAU,IAAIjD,OAAJ,EAAhB;AACAiD,gBAAQC,QAAR,CAAiB9B,aAAjB;AACA,YAAM+B,aAAaF,QAAQG,IAAR,CAAa/D,IAAb,CAAnB;AACAiC,gBAAQqB,KAAKC,GAAL,CAAStB,KAAT,EAAgB6B,WAAW7B,KAA3B,CAAR;AACD,OALD,MAKO;AACLA,gBAAQgB,QAAR;AACD;AACF;;AAEDf;AACA,QAAIA,SAAS1B,SAAT,KAAuB,CAA3B,EAA8B;AAC5BF,UAAI;AACF0D,0BAAkBhD,UADhB;AAEFA,oBAAYkB,MAFV;AAGFC,sCAHE;AAIF8B,wBAAgBlC,aAJd;AAKFE,oBALE,EAKKb,wBALL,EAAJ;AAMD;AACF;;AAEDnB,MAAI4D,QAAJ,CAAa9B,aAAb;AACA,MAAMmC,QAAQ9D,KAAKC,GAAL,EAAd;AACA,MAAM8D,YAAYD,QAAQ/D,OAA1B;AACA,SAAO;AACL6D,sBAAkBhD,UADb;AAELA,gBAAYkB,MAFP;AAGLC,kCAHK;AAIL8B,oBAAgBlC,aAJX;AAKLE,gBALK,EAKEb,wBALF,EAKe+C,oBALf,EAAP;AAMD;;AAEM,SAASxE,eAAT,CAAyByE,YAAzB,EAAuCnE,GAAvC,EAA4CD,IAA5C,EAAkD;AACvD,MAAMS,WAAW2D,aAAa3D,QAAb,IAAyB,EAA1C;AACA,MAAI4D,cAAc5D,SAASU,OAA3B;AACA,MAAI,CAACkD,WAAD,IAAgBzC,OAAO0C,SAAP,CAAiBD,WAAjB,CAApB,EAAmD;AACjD,QAAME,cAAc3D,OAAOC,cAAP,CAAsBZ,GAAtB,EAA2Ba,WAA3B,CAAuC0D,IAA3D;AACA,QAAIC,iBAAiB,EAArB;AACAA,mBAAeF,WAAf,IAA8BF,eAAe,CAA7C;AACAA,kBAAcI,cAAd;AACD;;AAED,MAAIC,WAAW,CAAf;AACA,MAAIC,cAAc,CAAlB;AACA,MAAIC,QAAQ,EAAZ;AACA,MAAIC,eAAe,CAAnB;AACA,OAAK,IAAIC,OAAT,IAAoBT,WAApB,EAAiC;AAC/B,QAAMU,SAASV,YAAYS,OAAZ,CAAf;AACA,QAAI1D,cAAc,CAAlB;AACA,QAAI4D,aAAa,IAAjB;AACA,QAAI,QAAOD,MAAP,yCAAOA,MAAP,OAAkB,QAAtB,EAAgC;AAC9B,UAAIE,gBAAgBF,OAAOE,aAA3B;AACA7D,oBAAc2D,OAAO5D,OAAP,IAAkB,CAAhC;AACA,UAAM+D,mBAAmB5B,KAAKE,GAAL,CAASuB,OAAOG,gBAAP,IAA2B,CAApC,EAAuClF,KAAKqB,MAAL,GAAcqD,QAArD,CAAzB;;AAEA,UAAIQ,gBAAJ,EAAsB;AACpBP,uBAAevD,WAAf;AACA,YAAI+D,eAAenF,KAAK0D,KAAL,CAAWgB,QAAX,EAAqBQ,gBAArB,CAAnB;AACAF,qBAAa,yBAAUG,YAAV,EAAwB/D,WAAxB,EAAqC6D,aAArC,CAAb;AACAP,oBAAYQ,gBAAZ;AACD;AACF,KAXD,MAWO,IAAItD,OAAO0C,SAAP,CAAiBS,MAAjB,CAAJ,EAA8B;AACnC3D,oBAAc2D,UAAU,CAAxB;AACD;AACDF,oBAAgBzD,WAAhB;;AAEAwD,UAAMjC,IAAN,CAAW,EAACF,MAAMqC,OAAP,EAAgB1D,wBAAhB,EAA6B4D,sBAA7B,EAAX;AACD;;AAED,MAAMI,gBAAgBP,eAAeF,WAArC;AACA,MAAIS,aAAJ,EAAmB;AACjB,QAAMC,gBAAgBX,aAAa,CAAb,GAAiB1E,IAAjB,GAAwBA,KAAK0D,KAAL,CAAWgB,QAAX,CAA9C;AACA,QAAMO,iBAAgBxE,SAASwE,aAAT,IAA0B,CAAhD;AACA,QAAMD,cAAa,yBAAUK,aAAV,EAAyBD,aAAzB,EAAwCH,cAAxC,CAAnB;AAHiB;AAAA;AAAA;;AAAA;AAIjB,4BAAiBL,KAAjB,mIAAwB;AAAA,YAAfnC,IAAe;;AACtB,YAAI,CAACA,KAAKuC,UAAV,EAAsB;AACpBvC,eAAKuC,UAAL,GAAkBA,YAAWM,MAAX,CAAkB,CAAlB,EAAqB7C,KAAKrB,WAA1B,CAAlB;AACD;AACF;AARgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AASjB,QAAI4D,YAAW3D,MAAX,GAAoB,CAAxB,EAA2B;AACzB,YAAM,IAAIkE,KAAJ,CAAU,qBAAV,CAAN;AACD;AACF;;AAED,MAAIpE,UAAU,EAAd;AApDuD;AAAA;AAAA;;AAAA;AAqDvD,0BAAiByD,KAAjB,mIAAwB;AAAA,UAAfnC,KAAe;;AACtB,UAAIuC,eAAavC,MAAKuC,UAAtB;AACA,WAAK,IAAI7B,IAAI,CAAb,EAAgBA,IAAIV,MAAKrB,WAAzB,EAAsC+B,GAAtC,EAA2C;AACzChC,gBAAQwB,IAAR,CAAa,EAACF,MAAMA,MAAKA,IAAZ,EAAkBC,WAAWsC,aAAWQ,KAAX,EAA7B,EAAb;AACD;AACF;AA1DsD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AA4DvD,SAAOrE,OAAP;AACD;;AAED,SAASqB,eAAT,CAAyBiD,OAAzB,EAAkCC,OAAlC,EAA2CP,YAA3C,EAAyDjF,SAAzD,EAAoE;AAClE,MAAMyF,UAAU9F,QAAQ,SAAR,EAAmB+F,OAAnC;AACA,MAAMC,OAAOF,QAAQF,OAAR,CAAb;AACA,MAAMrC,UAAU,IAAIyC,IAAJ,EAAhB;AACAzC,UAAQS,QAAR,CAAiB6B,OAAjB;AACA,MAAMrC,SAASD,QAAQ0C,KAAR,CAAcX,YAAd,EAA4BjF,SAA5B,CAAf;AACA,SAAO,EAACmD,cAAD,EAASD,gBAAT,EAAP;AACD;;AAED,SAASP,iBAAT,CAA2B4C,OAA3B,EAAoCC,OAApC,EAA6CP,YAA7C,EAA2DjF,SAA3D,EAAsE;AACpE,MAAMyF,UAAU9F,QAAQ,SAAR,EAAmB+F,OAAnC;AACA,SAAO,IAAIhD,OAAJ,CAAY,UAAC7C,OAAD,EAAUgG,MAAV,EAAqB;AACtCjG,YAAQ,EAAC2F,gBAAD,EAAUC,gBAAV,EAAmBP,0BAAnB,EAAiCjF,oBAAjC,EAAR,EAAqD,UAAC+B,KAAD,EAAQa,OAAR,EAAoB;AACvE,UAAIb,KAAJ,EAAW;AACT,eAAO8D,OAAO9D,KAAP,CAAP;AACD;;AAED,UAAMmB,UAAU,IAAIuC,QAAQF,OAAR,CAAJ,EAAhB;AACArC,cAAQS,QAAR,CAAiBf,QAAQmB,cAAzB;;AAEAlE,cAAQ,EAACqD,gBAAD,EAAUC,QAAQP,QAAQO,MAA1B,EAAR;AACD,KATD;AAUD,GAXM,CAAP;AAYD","file":"parallel-trainer.js","sourcesContent":["import partition from './utilities/partition';\nconst workerFarm = require('worker-farm');\nconst workers    = workerFarm(require.resolve('./parallel-trainer-worker'));\n\n/**\n * Ensemble training, via simple parameter averaging.\n */\nexport async function trainParallel(data, net, trainOpts = {}) {\n  const startMs = Date.now();\n  const log = (trainOpts.log === true ? console.log : trainOpts.log) || (() => {});\n  const logPeriod = trainOpts.logPeriod || 1;\n  const parallel = trainOpts.parallel || {};\n  const threadLog = parallel.log === true ? console.log : parallel.log || false;\n  const NetCtor = Object.getPrototypeOf(net).constructor;\n  const maxEpochs = trainOpts.iterations || 1000;\n  const errorThresh = trainOpts.errorThresh || NetCtor.trainDefaults.errorThresh;\n  const threads = unpackTrainOpts(trainOpts, net, data);\n  const threadCount = threads.length;\n\n  let threadTrainOpts = Object.assign({}, trainOpts);\n  delete threadTrainOpts.parallel;\n  delete threadTrainOpts.callback;\n  threadTrainOpts.iterations = parallel.iterationsPerThread || 10;\n  threadTrainOpts.log = threadLog;\n  threadTrainOpts.logPeriod = parallel.logPeriod || 1;\n  threadTrainOpts.timeout = !threadTrainOpts.timeout || threadTrainOpts.timeout === Infinity ? Number.MAX_SAFE_INTEGER : threadTrainOpts.timeout;\n  \n  net.verifyIsInitialized(data);\n  let globalWeights = net.toJSON();\n\n  let error = 1;\n  let epochs = 0;\n  let iterations = 0;\n  let itemIterations = 0;\n\n  while (epochs < maxEpochs && error >= errorThresh) {\n    let promises = [];\n\n    for (let thread of threads) {\n      if (parallel.synchronous === true) {\n        let result = runTrainingSync(thread.type, globalWeights, thread.partition, threadTrainOpts);\n        promises.push(Promise.resolve(result));\n      } else {\n        promises.push(runTrainingWorker(thread.type, globalWeights, thread.partition, threadTrainOpts));\n      }\n    }\n\n    const results = await Promise.all(promises);\n    let maxError, minError;\n    let trainedNets = [];\n    for (let t = 0; t < threadCount; t++) {\n      const trained = results[t].trained;\n      const status = results[t].status;\n      maxError = t === 0 ? status.error : Math.max(maxError, status.error);\n      minError = t === 0 ? status.error : Math.min(minError, status.error);\n      trainedNets.push(trained);\n      iterations += status.iterations;\n      itemIterations += status.iterations * threads[t].partition.length;\n    }\n\n    globalWeights = trainedNets[0].avg(...trainedNets.slice(1)).toJSON();\n\n    error = maxError;\n    if (minError <= errorThresh) {\n      if (parallel.errorMode === 'test') {\n        const testnet = new NetCtor();\n        testnet.fromJSON(globalWeights);\n        const testResult = testnet.test(data);\n        error = Math.max(error, testResult.error);\n      } else {\n        error = minError;\n      }\n    }\n    \n    epochs++;\n    if (epochs % logPeriod === 0) {\n      log({\n        threadIterations: iterations,\n        iterations: epochs,\n        itemIterations,\n        trainedNetJSON: globalWeights,\n        error, threadCount});\n    }\n  }\n\n  net.fromJSON(globalWeights);\n  const endMs = Date.now();\n  const elapsedMs = endMs - startMs;\n  return {\n    threadIterations: iterations,\n    iterations: epochs,\n    itemIterations,\n    trainedNetJSON: globalWeights,\n    error, threadCount, elapsedMs};\n}\n\nexport function unpackTrainOpts(trainOptions, net, data) {\n  const parallel = trainOptions.parallel || {};\n  let threadsOpts = parallel.threads;\n  if (!threadsOpts || Number.isInteger(threadsOpts)) {\n    const netCtorName = Object.getPrototypeOf(net).constructor.name;\n    let threadsOptsObj = {};\n    threadsOptsObj[netCtorName] = threadsOpts || 1;\n    threadsOpts = threadsOptsObj;\n  }\n\n  let dataUsed = 0;\n  let partitioned = 0;\n  let types = [];\n  let totalThreads = 0;\n  for (let netName in threadsOpts) {\n    const config = threadsOpts[netName];\n    let threadCount = 1;\n    let partitions = null;\n    if (typeof config === \"object\") {\n      let partitionSize = config.partitionSize;\n      threadCount = config.threads || 1;\n      const trainingDataSize = Math.min(config.trainingDataSize || 0, data.length - dataUsed);\n\n      if (trainingDataSize) {\n        partitioned += threadCount;\n        let trainingData = data.slice(dataUsed, trainingDataSize);\n        partitions = partition(trainingData, threadCount, partitionSize);\n        dataUsed += trainingDataSize;\n      }\n    } else if (Number.isInteger(config)) {\n      threadCount = config || 1;\n    }\n    totalThreads += threadCount;\n\n    types.push({type: netName, threadCount, partitions});\n  }\n\n  const unpartitioned = totalThreads - partitioned;\n  if (unpartitioned) {\n    const remainingData = dataUsed === 0 ? data : data.slice(dataUsed);\n    const partitionSize = parallel.partitionSize || 1;\n    const partitions = partition(remainingData, unpartitioned, partitionSize);\n    for (let type of types) {\n      if (!type.partitions) {\n        type.partitions = partitions.splice(0, type.threadCount);\n      }\n    }\n    if (partitions.length > 0) {\n      throw new Error('Too many partitions');\n    }\n  }\n\n  let threads = [];\n  for (let type of types) {\n    let partitions = type.partitions;\n    for (let t = 0; t < type.threadCount; t++) {\n      threads.push({type: type.type, partition: partitions.shift()});\n    }\n  }\n\n  return threads;\n}\n\nfunction runTrainingSync(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  const ctor = brainjs[netType];\n  const trained = new ctor();\n  trained.fromJSON(netJSON);\n  const status = trained.train(trainingData, trainOpts);\n  return {status, trained};\n}\n\nfunction runTrainingWorker(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  return new Promise((resolve, reject) => {\n    workers({netType, netJSON, trainingData, trainOpts}, (error, results) => {\n      if (error) {\n        return reject(error);\n      }\n\n      const trained = new brainjs[netType]();\n      trained.fromJSON(results.trainedNetJSON);\n\n      resolve({trained, status: results.status});\n    });\n  });\n}\n"]}