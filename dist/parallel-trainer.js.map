{"version":3,"sources":["../src/parallel-trainer.js"],"names":["trainParallel","unpackTrainOpts","workerFarm","require","workers","resolve","data","net","trainOptions","startMs","Date","now","log","console","logPeriod","parallel","NetCtor","Object","getPrototypeOf","constructor","maxEpochs","epochs","errorThresh","trainDefaults","threads","threadCount","length","peerTrainOptions","assign","callback","train","iterations","globalWeights","toJSON","error","itemIterations","promises","thread","syncMode","result","runTrainingSync","type","partition","push","Promise","runTrainingWorker","results","all","worstError","trainedNets","t","trained","status","partitionIdx","test","Math","max","avg","slice","fromJSON","endMs","elapsedMs","threadsOpts","Number","isInteger","netCtorName","name","threadsOptsObj","dataUsed","partitioned","types","totalThreads","netName","config","partitions","partitionSize","trainingDataSize","min","trainingData","unpartitioned","remainingData","splice","Error","shift","netType","netJSON","trainOpts","brainjs","default","ctor","reject","trainedNetJSON"],"mappings":";;;;;;;;QAOsBA,a,GAAAA,a;QAgENC,e,GAAAA,e;;AAvEhB;;;;;;;;AACA,IAAMC,aAAaC,QAAQ,aAAR,CAAnB;AACA,IAAMC,UAAaF,WAAWC,QAAQE,OAAR,CAAgB,2BAAhB,CAAX,CAAnB;;AAEA;;;AAGO,eAAeL,aAAf,CAA6BM,IAA7B,EAAmCC,GAAnC,EAA2D;AAAA,MAAnBC,YAAmB,uEAAJ,EAAI;;AAChE,MAAMC,UAAUC,KAAKC,GAAL,EAAhB;AACA,MAAMC,MAAM,CAACJ,aAAaI,GAAb,KAAqB,IAArB,GAA4BC,QAAQD,GAApC,GAA0CJ,aAAaI,GAAxD,KAAiE,YAAM,CAAE,CAArF;AACA,MAAME,YAAYN,aAAaM,SAAb,IAA0B,CAA5C;AACA,MAAMC,WAAWP,aAAaO,QAAb,IAAyB,EAA1C;AACA,MAAMC,UAAUC,OAAOC,cAAP,CAAsBX,GAAtB,EAA2BY,WAA3C;AACA,MAAMC,YAAYL,SAASM,MAAT,IAAmB,IAArC;AACA,MAAMC,cAAcd,aAAac,WAAb,IAA4BN,QAAQO,aAAR,CAAsBD,WAAtE;AACA,MAAME,UAAUvB,gBAAgBO,YAAhB,EAA8BD,GAA9B,EAAmCD,IAAnC,CAAhB;AACA,MAAMmB,cAAcD,QAAQE,MAA5B;;AAEA,MAAIC,mBAAmBV,OAAOW,MAAP,CAAc,EAAd,EAAkBpB,YAAlB,CAAvB;AACA,SAAOmB,iBAAiBZ,QAAxB;AACA,SAAOY,iBAAiBE,QAAxB;AACA,SAAOF,iBAAiBf,GAAxB;;AAEAL,MAAIuB,KAAJ,CAAU,CAACxB,KAAK,CAAL,CAAD,CAAV,EAAqB,EAACgB,aAAa,GAAd,EAAmBS,YAAY,CAA/B,EAArB,EAhBgE,CAgBP;AACzD,MAAIC,gBAAgBzB,IAAI0B,MAAJ,EAApB;;AAEA,MAAIC,QAAQ,CAAZ;AACA,MAAIb,SAAS,CAAb;AACA,MAAIU,aAAa,CAAjB;AACA,MAAII,iBAAiB,CAArB;;AAEA,SAAOd,SAASD,SAAT,IAAsBc,SAASZ,WAAtC,EAAmD;AAAA;;AACjD,QAAIc,WAAW,EAAf;;AADiD;AAAA;AAAA;;AAAA;AAGjD,2BAAmBZ,OAAnB,8HAA4B;AAAA,YAAnBa,MAAmB;;AAC1B,YAAItB,SAASuB,QAAT,KAAsB,IAA1B,EAAgC;AAC9B,cAAIC,UAASC,gBAAgBH,OAAOI,IAAvB,EAA6BT,aAA7B,EAA4CK,OAAOK,SAAnD,EAA8Df,gBAA9D,CAAb;AACAS,mBAASO,IAAT,CAAcC,QAAQvC,OAAR,CAAgBkC,OAAhB,CAAd;AACD,SAHD,MAGO;AACLH,mBAASO,IAAT,CAAcE,kBAAkBR,OAAOI,IAAzB,EAA+BT,aAA/B,EAA8CK,OAAOK,SAArD,EAAgEf,gBAAhE,CAAd;AACD;AACF;AAVgD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAYjD,QAAMmB,UAAU,MAAMF,QAAQG,GAAR,CAAYX,QAAZ,CAAtB;AACA,QAAIY,aAAa,CAAjB;AACA,QAAIC,cAAc,EAAlB;AACA,SAAK,IAAIC,IAAIzB,cAAc,CAA3B,EAA8ByB,KAAK,CAAnC,EAAsCA,GAAtC,EAA2C;AACzC,UAAMC,UAAUL,QAAQI,CAAR,EAAWC,OAA3B;AACA,UAAMC,SAASN,QAAQI,CAAR,EAAWE,MAA1B;AACAH,kBAAYN,IAAZ,CAAiBQ,OAAjB;AACA,UAAME,eAAe,CAACH,MAAM,CAAN,GAAUzB,WAAV,GAAwByB,CAAzB,IAA8B,CAAnD;AACA,UAAMX,SAASY,QAAQG,IAAR,CAAa9B,QAAQ6B,YAAR,EAAsBX,SAAtB,CAAgC,CAAhC,CAAb,CAAf;AACAM,mBAAaO,KAAKC,GAAL,CAASjB,OAAOL,KAAhB,EAAuBc,UAAvB,CAAb;AACAjB,oBAAcqB,OAAOrB,UAArB;AACAI,wBAAkBiB,OAAOrB,UAAP,GAAoBP,QAAQ0B,CAAR,EAAWR,SAAX,CAAqBhB,MAA3D;AACD;AACDQ,YAAQc,UAAR;AACA3B;AACA,QAAIA,SAASP,SAAT,KAAuB,CAA3B,EAA8B;AAC5BF,UAAI,EAACmB,sBAAD,EAAaG,YAAb,EAAoBb,cAApB,EAA4Bc,8BAA5B,EAA4CV,wBAA5C,EAAJ;AACD;;AAEDO,oBAAgB,6BAAY,CAAZ,GAAeyB,GAAf,yCAAsBR,YAAYS,KAAZ,CAAkB,CAAlB,CAAtB,GAA4CzB,MAA5C,EAAhB;AACD;;AAED1B,MAAIoD,QAAJ,CAAa3B,aAAb;AACA,MAAM4B,QAAQlD,KAAKC,GAAL,EAAd;AACA,MAAMkD,YAAYD,QAAQnD,OAA1B;AACA,SAAO,EAACyB,YAAD,EAAQH,sBAAR,EAAoBI,8BAApB,EAAoCd,cAApC,EAA4CI,wBAA5C,EAAyDoC,oBAAzD,EAAP;AACD;;AAEM,SAAS5D,eAAT,CAAyBO,YAAzB,EAAuCD,GAAvC,EAA4CD,IAA5C,EAAkD;AACvD,MAAMS,WAAWP,aAAaO,QAAb,IAAyB,EAA1C;AACA,MAAI+C,cAAc/C,SAASS,OAA3B;AACA,MAAI,CAACsC,WAAD,IAAgBC,OAAOC,SAAP,CAAiBF,WAAjB,CAApB,EAAmD;AACjD,QAAMG,cAAchD,OAAOC,cAAP,CAAsBX,GAAtB,EAA2BY,WAA3B,CAAuC+C,IAA3D;AACA,QAAIC,iBAAiB,EAArB;AACAA,mBAAeF,WAAf,IAA8BH,eAAe,CAA7C;AACAA,kBAAcK,cAAd;AACD;;AAED,MAAIC,WAAW,CAAf;AACA,MAAIC,cAAc,CAAlB;AACA,MAAIC,QAAQ,EAAZ;AACA,MAAIC,eAAe,CAAnB;AACA,OAAK,IAAIC,OAAT,IAAoBV,WAApB,EAAiC;AAC/B,QAAMW,SAASX,YAAYU,OAAZ,CAAf;AACA,QAAI/C,cAAc,CAAlB;AACA,QAAIiD,aAAa,IAAjB;AACA,QAAI,QAAOD,MAAP,yCAAOA,MAAP,OAAkB,QAAtB,EAAgC;AAC9B,UAAIE,gBAAgBF,OAAOE,aAA3B;AACAlD,oBAAcgD,OAAOjD,OAAP,IAAkB,CAAhC;AACA,UAAMoD,mBAAmBrB,KAAKsB,GAAL,CAASJ,OAAOG,gBAAP,IAA2B,CAApC,EAAuCtE,KAAKoB,MAAL,GAAc0C,QAArD,CAAzB;;AAEA,UAAIQ,gBAAJ,EAAsB;AACpBP,uBAAe5C,WAAf;AACA,YAAIqD,eAAexE,KAAKoD,KAAL,CAAWU,QAAX,EAAqBQ,gBAArB,CAAnB;AACAF,qBAAa,yBAAUI,YAAV,EAAwBrD,WAAxB,EAAqCkD,aAArC,CAAb;AACAP,oBAAYQ,gBAAZ;AACD;AACF,KAXD,MAWO,IAAIb,OAAOC,SAAP,CAAiBS,MAAjB,CAAJ,EAA8B;AACnChD,oBAAcgD,UAAU,CAAxB;AACD;AACDF,oBAAgB9C,WAAhB;;AAEA6C,UAAM3B,IAAN,CAAW,EAACF,MAAM+B,OAAP,EAAgB/C,wBAAhB,EAA6BiD,sBAA7B,EAAX;AACD;;AAED,MAAMK,gBAAgBR,eAAeF,WAArC;AACA,MAAIU,aAAJ,EAAmB;AACjB,QAAMC,gBAAgBZ,aAAa,CAAb,GAAiB9D,IAAjB,GAAwBA,KAAKoD,KAAL,CAAWU,QAAX,CAA9C;AACA,QAAMO,iBAAgB5D,SAAS4D,aAAT,IAA0B,CAAhD;AACA,QAAMD,cAAa,yBAAUM,aAAV,EAAyBD,aAAzB,EAAwCJ,cAAxC,CAAnB;AAHiB;AAAA;AAAA;;AAAA;AAIjB,4BAAiBL,KAAjB,mIAAwB;AAAA,YAAf7B,IAAe;;AACtB,YAAI,CAACA,KAAKiC,UAAV,EAAsB;AACpBjC,eAAKiC,UAAL,GAAkBA,YAAWO,MAAX,CAAkB,CAAlB,EAAqBxC,KAAKhB,WAA1B,CAAlB;AACD;AACF;AARgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AASjB,QAAIiD,YAAWhD,MAAX,GAAoB,CAAxB,EAA2B;AACzB,YAAM,IAAIwD,KAAJ,CAAU,qBAAV,CAAN;AACD;AACF;;AAED,MAAI1D,UAAU,EAAd;AApDuD;AAAA;AAAA;;AAAA;AAqDvD,0BAAiB8C,KAAjB,mIAAwB;AAAA,UAAf7B,KAAe;;AACtB,UAAIiC,eAAajC,MAAKiC,UAAtB;AACA,WAAK,IAAIxB,IAAI,CAAb,EAAgBA,IAAIT,MAAKhB,WAAzB,EAAsCyB,GAAtC,EAA2C;AACzC1B,gBAAQmB,IAAR,CAAa,EAACF,MAAMA,MAAKA,IAAZ,EAAkBC,WAAWgC,aAAWS,KAAX,EAA7B,EAAb;AACD;AACF;AA1DsD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AA4DvD,SAAO3D,OAAP;AACD;;AAED,SAASgB,eAAT,CAAyB4C,OAAzB,EAAkCC,OAAlC,EAA2CP,YAA3C,EAAyDQ,SAAzD,EAAoE;AAClE,MAAMC,UAAUpF,QAAQ,SAAR,EAAmBqF,OAAnC;AACA,MAAMC,OAAOF,QAAQH,OAAR,CAAb;AACA,MAAMjC,UAAU,IAAIsC,IAAJ,EAAhB;AACAtC,UAAQQ,QAAR,CAAiB0B,OAAjB;AACA,MAAMjC,SAASD,QAAQrB,KAAR,CAAcgD,YAAd,EAA4BQ,SAA5B,CAAf;AACA,SAAO,EAAClC,cAAD,EAASD,gBAAT,EAAP;AACD;;AAED,SAASN,iBAAT,CAA2BuC,OAA3B,EAAoCC,OAApC,EAA6CP,YAA7C,EAA2DQ,SAA3D,EAAsE;AACpE,MAAMC,UAAUpF,QAAQ,SAAR,EAAmBqF,OAAnC;AACA,SAAO,IAAI5C,OAAJ,CAAY,UAACvC,OAAD,EAAUqF,MAAV,EAAqB;AACtCtF,YAAQ,EAACgF,gBAAD,EAAUC,gBAAV,EAAmBP,0BAAnB,EAAiCQ,oBAAjC,EAAR,EAAqD,UAACpD,KAAD,EAAQY,OAAR,EAAoB;AACvE,UAAIZ,KAAJ,EAAW;AACT,eAAOwD,OAAOxD,KAAP,CAAP;AACD;;AAED,UAAMiB,UAAU,IAAIoC,QAAQH,OAAR,CAAJ,EAAhB;AACAjC,cAAQQ,QAAR,CAAiBb,QAAQ6C,cAAzB;;AAEAtF,cAAQ,EAAC8C,gBAAD,EAAUC,QAAQN,QAAQM,MAA1B,EAAR;AACD,KATD;AAUD,GAXM,CAAP;AAYD","file":"parallel-trainer.js","sourcesContent":["import partition from './utilities/partition';\nconst workerFarm = require('worker-farm');\nconst workers    = workerFarm(require.resolve('./parallel-trainer-worker'));\n\n/**\n * Ensemble training, via simple parameter averaging.\n */\nexport async function trainParallel(data, net, trainOptions = {}) {\n  const startMs = Date.now();\n  const log = (trainOptions.log === true ? console.log : trainOptions.log) || (() => {});\n  const logPeriod = trainOptions.logPeriod || 1;\n  const parallel = trainOptions.parallel || {};\n  const NetCtor = Object.getPrototypeOf(net).constructor;\n  const maxEpochs = parallel.epochs || 1000;\n  const errorThresh = trainOptions.errorThresh || NetCtor.trainDefaults.errorThresh;\n  const threads = unpackTrainOpts(trainOptions, net, data);\n  const threadCount = threads.length;\n\n  let peerTrainOptions = Object.assign({}, trainOptions);\n  delete peerTrainOptions.parallel;\n  delete peerTrainOptions.callback;\n  delete peerTrainOptions.log;\n  \n  net.train([data[0]], {errorThresh: 0.9, iterations: 1}); // initialize weights\n  let globalWeights = net.toJSON();\n\n  let error = 1;\n  let epochs = 0;\n  let iterations = 0;\n  let itemIterations = 0;\n\n  while (epochs < maxEpochs && error >= errorThresh) {\n    let promises = [];\n\n    for (let thread of threads) {\n      if (parallel.syncMode === true) {\n        let result = runTrainingSync(thread.type, globalWeights, thread.partition, peerTrainOptions);\n        promises.push(Promise.resolve(result));\n      } else {\n        promises.push(runTrainingWorker(thread.type, globalWeights, thread.partition, peerTrainOptions));\n      }\n    }\n\n    const results = await Promise.all(promises);\n    let worstError = 0;\n    let trainedNets = [];\n    for (let t = threadCount - 1; t >= 0; t--) {\n      const trained = results[t].trained;\n      const status = results[t].status;\n      trainedNets.push(trained);\n      const partitionIdx = (t === 0 ? threadCount : t) - 1;\n      const result = trained.test(threads[partitionIdx].partition[0]);\n      worstError = Math.max(result.error, worstError);\n      iterations += status.iterations;\n      itemIterations += status.iterations * threads[t].partition.length;\n    }\n    error = worstError;\n    epochs++;\n    if (epochs % logPeriod === 0) {\n      log({iterations, error, epochs, itemIterations, threadCount});\n    }\n\n    globalWeights = trainedNets[0].avg(...trainedNets.slice(1)).toJSON();\n  }\n\n  net.fromJSON(globalWeights);\n  const endMs = Date.now();\n  const elapsedMs = endMs - startMs;\n  return {error, iterations, itemIterations, epochs, threadCount, elapsedMs};\n}\n\nexport function unpackTrainOpts(trainOptions, net, data) {\n  const parallel = trainOptions.parallel || {};\n  let threadsOpts = parallel.threads;\n  if (!threadsOpts || Number.isInteger(threadsOpts)) {\n    const netCtorName = Object.getPrototypeOf(net).constructor.name;\n    let threadsOptsObj = {};\n    threadsOptsObj[netCtorName] = threadsOpts || 1;\n    threadsOpts = threadsOptsObj;\n  }\n\n  let dataUsed = 0;\n  let partitioned = 0;\n  let types = [];\n  let totalThreads = 0;\n  for (let netName in threadsOpts) {\n    const config = threadsOpts[netName];\n    let threadCount = 1;\n    let partitions = null;\n    if (typeof config === \"object\") {\n      let partitionSize = config.partitionSize;\n      threadCount = config.threads || 1;\n      const trainingDataSize = Math.min(config.trainingDataSize || 0, data.length - dataUsed);\n\n      if (trainingDataSize) {\n        partitioned += threadCount;\n        let trainingData = data.slice(dataUsed, trainingDataSize);\n        partitions = partition(trainingData, threadCount, partitionSize);\n        dataUsed += trainingDataSize;\n      }\n    } else if (Number.isInteger(config)) {\n      threadCount = config || 1;\n    }\n    totalThreads += threadCount;\n\n    types.push({type: netName, threadCount, partitions});\n  }\n\n  const unpartitioned = totalThreads - partitioned;\n  if (unpartitioned) {\n    const remainingData = dataUsed === 0 ? data : data.slice(dataUsed);\n    const partitionSize = parallel.partitionSize || 1;\n    const partitions = partition(remainingData, unpartitioned, partitionSize);\n    for (let type of types) {\n      if (!type.partitions) {\n        type.partitions = partitions.splice(0, type.threadCount);\n      }\n    }\n    if (partitions.length > 0) {\n      throw new Error('Too many partitions');\n    }\n  }\n\n  let threads = [];\n  for (let type of types) {\n    let partitions = type.partitions;\n    for (let t = 0; t < type.threadCount; t++) {\n      threads.push({type: type.type, partition: partitions.shift()});\n    }\n  }\n\n  return threads;\n}\n\nfunction runTrainingSync(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  const ctor = brainjs[netType];\n  const trained = new ctor();\n  trained.fromJSON(netJSON);\n  const status = trained.train(trainingData, trainOpts);\n  return {status, trained};\n}\n\nfunction runTrainingWorker(netType, netJSON, trainingData, trainOpts) {\n  const brainjs = require('./index').default;\n  return new Promise((resolve, reject) => {\n    workers({netType, netJSON, trainingData, trainOpts}, (error, results) => {\n      if (error) {\n        return reject(error);\n      }\n\n      const trained = new brainjs[netType]();\n      trained.fromJSON(results.trainedNetJSON);\n\n      resolve({trained, status: results.status});\n    });\n  });\n}\n"]}